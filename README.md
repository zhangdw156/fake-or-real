## Kaggle比赛，Fake or Real: The Impostor Hunt in Texts

### 尝试1

直接把两个文本都放到prompt，让大模型判断文本1还是文本2是真的。

由于文本太长了，所以模型的效果很差。

在训练集上：

- 0.6B的模型，微调后的准确率为0.97895
- 4B 的模型，微调后的准确率为0.96842
- 8B 的模型，微调后的准确率为0.97895
- 14B的模型，微调后的准确率为0.96842

~而排行榜上的最高分为0.93153，可见目前的策略绝对行不通。~

搞错了，之前验证的时候忘记加lora了，这么看效果还可以。

```shell
submission_Qwen3-14B_sft.csv
0.91078

submission_Qwen3-8B_sft.csv
0.91701

submission_Qwen3-0.6B_sft.csv
0.85892
```

Nice! The Bigger, the Better! 

目前可以确定，在不改变数据集的情况下，8B的模型效果最好。

下一步思路：

- 在原始数据上进行数据增强
- 引入思维链
- 尝试32B的模型

使用数据增强，也只有0.91493分，看来这条路不行

使用了更长的sys_prompt，得分高了一点。

```shell
submission_Qwen3-8B_sft (2).csv
0.92323
```

有点违反常理，我用prompt1训练出的模型，在prompt2的测试集上，效果更好，比prompt1 on prompt1和prompt2 on prompt2效果都好，这是为什么？减少了过拟合？

### 尝试2

直接让大模型对文本分别打分，得分高的为真的。

在训练集上，0.6B的模型，微调之后，方差很大。

```shell
第1次验证
2025-07-12 15:03:03,045 - __main__ - INFO - 在训练集上的准确率为: 0.23158
第2次验证
2025-07-12 15:03:19,951 - __main__ - INFO - 在训练集上的准确率为: 0.52632
第3次验证
2025-07-12 15:03:37,078 - __main__ - INFO - 在训练集上的准确率为: 0.29474
第4次验证
2025-07-12 15:03:53,942 - __main__ - INFO - 在训练集上的准确率为: 0.72632
第5次验证
2025-07-12 15:04:10,889 - __main__ - INFO - 在训练集上的准确率为: 0.65263
```

效果也不好呀！