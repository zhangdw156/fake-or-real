{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c749db1-55d8-448d-986a-0d3c597e8516",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f6ff5ed-bd4a-481a-9470-7a3bd5a4ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4e64f6-b322-4c0d-b6b1-2b3246d91567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dir='data/train'\n",
    "train_data=pd.read_csv('data/train.csv')\n",
    "pattern_file = r'^file_\\d+\\.txt$'\n",
    "pattern_dir=r'^article_\\d+$'\n",
    "for path in os.listdir(train_dir):\n",
    "    if re.match(pattern_dir, path):\n",
    "        article_path=os.path.join(train_dir,path)\n",
    "        # print(article_path)\n",
    "        for filename in os.listdir(article_path):\n",
    "            if re.match(pattern_file, filename):\n",
    "                # print(filename,int(article_path.split('_')[-1]))\n",
    "                with open(os.path.join(article_path,filename),'r') as f:\n",
    "                    train_data.loc[int(article_path.split('_')[-1]),filename.split('.')[0]]=f.read()\n",
    "train_data.to_json('data/train.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d115b504-2dec-4946-af4c-25e31c51b920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dir='data/test'\n",
    "test_data=pd.DataFrame()\n",
    "pattern_file = r'^file_\\d+\\.txt$'\n",
    "pattern_dir=r'^article_\\d+$'\n",
    "for path in os.listdir(test_dir):\n",
    "    if re.match(pattern_dir, path):\n",
    "        article_path=os.path.join(test_dir,path)\n",
    "        # print(article_path)\n",
    "        for filename in os.listdir(article_path):\n",
    "            if re.match(pattern_file, filename):\n",
    "                # print(filename,int(article_path.split('_')[-1]))\n",
    "                with open(os.path.join(article_path,filename),'r') as f:\n",
    "                    test_data.loc[int(article_path.split('_')[-1]),filename.split('.')[0]]=f.read()\n",
    "                    test_data.loc[int(article_path.split('_')[-1]),'id']=int(article_path.split('_')[-1])\n",
    "test_data.to_json('data/test.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a1923-2dea-40cc-b1b0-3ddbcb2dd8ee",
   "metadata": {},
   "source": [
    "## 准备构造微调数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7043f20e-58b7-4cf6-9945-70aeccf8f0b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_1</th>\n",
       "      <th>file_2</th>\n",
       "      <th>real_text_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Believe it or not, unless you directly contac...</td>\n",
       "      <td>This could include filing a lawsuit against t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sanskrit, as one of the oldest Indo-European ...</td>\n",
       "      <td>Medically speaking a seizure is when the elec...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Shirley Temple short subject would likely c...</td>\n",
       "      <td>- If you criminalize alcohol / drug use or sm...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It 's three fold : * Stuff is cheaper to mass...</td>\n",
       "      <td>Miami's vibrant music scene has long been a m...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That 's the problem of consciousness : we jus...</td>\n",
       "      <td>Different religions have different ways of pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              file_1  \\\n",
       "0   Believe it or not, unless you directly contac...   \n",
       "1   Sanskrit, as one of the oldest Indo-European ...   \n",
       "2   A Shirley Temple short subject would likely c...   \n",
       "3   It 's three fold : * Stuff is cheaper to mass...   \n",
       "4   That 's the problem of consciousness : we jus...   \n",
       "\n",
       "                                              file_2  real_text_id  id  \n",
       "0   This could include filing a lawsuit against t...             1   0  \n",
       "1   Medically speaking a seizure is when the elec...             2   1  \n",
       "2   - If you criminalize alcohol / drug use or sm...             2   2  \n",
       "3   Miami's vibrant music scene has long been a m...             1   3  \n",
       "4   Different religions have different ways of pr...             1   4  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_json('data/extra_train.json',orient='records',lines=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a3a64ba8-63ea-4903-a769-a2513f1efbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real_text_id\n",
       "1    6546\n",
       "2    6546\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['real_text_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bf67c7e8-0198-445f-b891-54d50d7e3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt=''\n",
    "with open('sys_prompt.txt','r') as f:\n",
    "    sys_prompt=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "efc83101-eec6-41e8-966e-04f20073dc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your task: Compare Text 1 and Text 2, then determine which one is factually correct (true) and which has been modified (false).\\n\\nText 1:\\n<text1>\\n{TEXT1}\\n</text1>\\n\\nText 2:\\n<text2>\\n{TEXT2}\\n</text2>\\n\\nEvaluation criteria:\\n- Check for factual accuracy\\n- Verify logical consistency\\n- Cross-reference with common knowledge\\n\\nIMPORTANT: Your final answer MUST be EITHER \"1\" OR \"2\". No explanations, comments, or additional information. Only the number.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0dca4651-a406-494a-a207-3d2650c91fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data['prompt'] = train_data.apply(lambda row: sys_prompt.format(TEXT1=row['file_1'],TEXT2=row['file_2']), axis=1)\n",
    "train_data=train_data.rename(columns={'real_text_id':'completion'})\n",
    "train_data['completion']=train_data['completion'].astype(str)\n",
    "train_data=train_data[['prompt','completion']]\n",
    "train_data.to_json('data/extra_train_processed.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1134a564-3652-4a55-8698-596f9471a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 测试集\n",
    "test_data=pd.read_json('data/test.json',orient='record',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a043c81-6068-4543-a7de-bd34f244a0ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data['prompt'] = test_data.apply(lambda row: sys_prompt.format(TEXT1=row['file_1'],TEXT2=row['file_2']), axis=1)\n",
    "test_data=test_data[['id','prompt']]\n",
    "test_data.sort_values(by='id', inplace=True)\n",
    "test_data.to_csv('data/test_processed.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcaa1197-0e7c-4222-af34-fe80d1d21e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>581</td>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>207</td>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656</td>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134</td>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>516</td>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>448</td>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>947</td>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>820</td>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>771</td>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1068 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                             prompt\n",
       "0     581  Your task: Compare Text 1 and Text 2, then det...\n",
       "1     207  Your task: Compare Text 1 and Text 2, then det...\n",
       "2     656  Your task: Compare Text 1 and Text 2, then det...\n",
       "3     134  Your task: Compare Text 1 and Text 2, then det...\n",
       "4     360  Your task: Compare Text 1 and Text 2, then det...\n",
       "...   ...                                                ...\n",
       "1063  516  Your task: Compare Text 1 and Text 2, then det...\n",
       "1064  448  Your task: Compare Text 1 and Text 2, then det...\n",
       "1065  947  Your task: Compare Text 1 and Text 2, then det...\n",
       "1066  820  Your task: Compare Text 1 and Text 2, then det...\n",
       "1067  771  Your task: Compare Text 1 and Text 2, then det...\n",
       "\n",
       "[1068 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81939566-547a-4005-9b84-900f4d94758c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your task: Compare Text 1 and Text 2, then det...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt completion\n",
       "0  Your task: Compare Text 1 and Text 2, then det...          1\n",
       "1  Your task: Compare Text 1 and Text 2, then det...          2\n",
       "2  Your task: Compare Text 1 and Text 2, then det...          1\n",
       "3  Your task: Compare Text 1 and Text 2, then det...          2\n",
       "4  Your task: Compare Text 1 and Text 2, then det...          2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "777a4d10-5f85-4fb8-ac77-cff693a28774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最长的prompt，id为： 83\n",
      "最长的prompt，长度为： 42413\n"
     ]
    }
   ],
   "source": [
    "longest_idx = train_data['prompt'].str.len().idxmax()\n",
    "print(\"最长的prompt，id为：\",longest_idx)\n",
    "print(\"最长的prompt，长度为：\",len(train_data.loc[longest_idx, 'prompt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db9541-8b6d-43ec-be49-1a2a4126423b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 先尝试推理一波"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc560b29-579b-4fdb-aaf0-8ea5264af67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='/data/download-model'\n",
    "model_name='Qwen3-0.6B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91e81829-80f9-4ba7-a528-60d1638035d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e5e2b6c-8af2-40ee-9a1b-1dd2ee416259",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=os.path.join(model_dir,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdae7aac-05d3-4167-b8ed-c97ab557be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from unsloth import FastLanguageModel\n",
    "# import torch\n",
    "\n",
    "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "#     model_name = model_path,\n",
    "#     max_seq_length = 40960,   # Context length - can be longer, but uses more memory\n",
    "#     # load_in_4bit = True,     # 4bit uses much less memory\n",
    "#     # load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
    "#     # full_finetuning = False, # We have full finetuning now!\n",
    "#     # token = \"hf_...\",      # use one if using gated models\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3e92be7-a964-4200-bb6b-489cc25a9a0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline,AutoModelForCausalLM,AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModelForCausalLM.from_pretrained(model_path).to('cuda:7')\n",
    "\n",
    "# model=PeftModel.from_pretrained(model,'model/sft')\n",
    "# model=model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e6a8312-fac6-4146-945b-f5691df2b885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:7\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\n",
    "    task=\"text-generation\",  # 指定任务类型\n",
    "    model=model,             # 传入预加载的模型\n",
    "    max_new_tokens=4,         # 其他参数\n",
    "    tokenizer=tokenizer,\n",
    "    device=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef2acf16-fcb5-468f-abb0-5e231f71ff51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['prompt', 'completion'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data=pd.read_json('data/train_processed.json',orient='records',lines=True)\n",
    "\n",
    "print(train_data.columns)\n",
    "train_data['text']=train_data.apply(\n",
    "    lambda row:\n",
    "        tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {'role':'user','content':row['prompt']}\n",
    "            ],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "            enable_thinking=False\n",
    "        ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38c6104f-2a63-4463-983c-4e29579e1ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs=generator(train_data['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0207a91f-84b3-43b0-85a4-a0274624309e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs=[row[0]['generated_text'][len(train_data.loc[idx,'text']):] for idx,row in enumerate(outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83245dd1-de88-402d-a477-b34e94d23fd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data['predict']=outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08268357-4bab-44f8-96a5-2ee3f235ee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率: 0.46316\n"
     ]
    }
   ],
   "source": [
    "train_data['completion']=train_data['completion'].astype(str)\n",
    "accuracy = (train_data['predict'] == train_data['completion']).mean()\n",
    "print(f\"准确率: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b388d-5b0b-4cd9-9808-d3559c182812",
   "metadata": {},
   "source": [
    "直接使用0.6B的模型，在训练集只有0.46316的准确率，如果是测试集的话，大概更低一点，距离最高分0.93153还差得远呢\n",
    "- sft， 0.48421？这不是基本没有提升吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89389de9-4942-4e0b-b701-1a31287b8be2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 尝试直接用sft微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe3cc2b-3f6b-4a4d-b83b-a1e722f8dec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fine/uv/transformers/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTConfig,SFTTrainer\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2610f71-a571-45da-ab91-4b8929bb58bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ds=load_dataset('json',data_files='data/train_processed.json',split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da9c2e8-825f-4ab1-b78f-f62520d18d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion'],\n",
       "    num_rows: 95\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ba6283f-8b49-49c7-a07d-6e5643346e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "model_dir='/data/download-model'\n",
    "model_name='Qwen3-4B'\n",
    "model_path=os.path.join(model_dir,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35855476-d88e-4e29-886f-68bc764234c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from unsloth import FastLanguageModel\n",
    "\n",
    "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "#     model_name = model_path,\n",
    "#     # max_seq_length = 40960,   # Context length - can be longer, but uses more memory\n",
    "#     # load_in_4bit = True,     # 4bit uses much less memory\n",
    "#     # load_in_8bit = False,    # A bit more accurate, uses 2x memory\n",
    "#     # full_finetuning = False, # We have full finetuning now!\n",
    "#     # token = \"hf_...\",      # use one if using gated models\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7aedeab-0a19-4cd1-aab6-f02677d207ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline,AutoModelForCausalLM,AutoTokenizer\n",
    "from peft import get_peft_model\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModelForCausalLM.from_pretrained(model_path).to('cuda:7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa37f347-ccd6-4833-942d-9462b081dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 源码里有apply_chat_template\n",
    "# train_ds=train_ds.map(lambda example:{\n",
    "#     'prompt':tokenizer.apply_chat_template(\n",
    "#         [\n",
    "#             {'role':'user','content':example['prompt']}\n",
    "#         ],\n",
    "#         tokenize=False,\n",
    "#         add_generation_prompt=True,\n",
    "#         enable_thinking=False\n",
    "#     )}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f805b960-4ae1-4c29-b9e3-3fb1e7d1ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config=LoraConfig(\n",
    "    r = 16,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 32,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = 0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e932bc1-2df3-407a-a078-b297395812ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swanlab\n",
    "\n",
    "swanlab.config.update({\n",
    "    \"model\": model_name\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5de12aa-756e-4da8-87a3-314bbdd8b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "average_tokens_across_devices is set to True but it is invalid when world size is1. Turn it to False automatically.\n"
     ]
    }
   ],
   "source": [
    "sft_config = SFTConfig(\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1, # Use GA to mimic batch size!\n",
    "    warmup_steps = 5,\n",
    "    num_train_epochs = 10, \n",
    "    learning_rate = 5e-5, \n",
    "    report_to = \"swanlab\", \n",
    "    completion_only_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f4b3b24-bcb0-476b-b3d3-e68c0255d9f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing train dataset: 100%|██████████| 95/95 [00:00<00:00, 226.87 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 95/95 [00:00<00:00, 26855.76 examples/s]\n",
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer=SFTTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    train_dataset = train_ds,\n",
    "    args=sft_config,\n",
    "    peft_config=lora_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed5b81d5-ce3e-483f-9dc3-22eb13f348d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 97, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/peft/peft_model.py\", line 818, in forward\n    return self.get_base_model()(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/utils/generic.py\", line 969, in wrapper\n    output = func(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 730, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n                                       ^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/utils/generic.py\", line 969, in wrapper\n    output = func(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 463, in forward\n    layer_outputs = decoder_layer(\n                    ^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/modeling_layers.py\", line 48, in __call__\n    return super().__call__(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 300, in forward\n    hidden_states = self.mlp(hidden_states)\n                    ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 90, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/peft/tuners/lora/layer.py\", line 727, in forward\n    result = result + lora_B(lora_A(dropout(x))) * scaling\n                                    ^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/functional.py\", line 1425, in dropout\n    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 94.99 GiB of which 7.31 MiB is free. Process 2156823 has 75.40 GiB memory in use. Including non-PyTorch memory, this process has 19.57 GiB memory in use. Of the allocated memory 18.42 GiB is allocated by PyTorch, and 175.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/transformers/trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/transformers/trainer.py:2555\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2548\u001b[39m context = (\n\u001b[32m   2549\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2551\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2552\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2553\u001b[39m )\n\u001b[32m   2554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2555\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2558\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2559\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2560\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2561\u001b[39m ):\n\u001b[32m   2562\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2563\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:864\u001b[39m, in \u001b[36mSFTTrainer.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    863\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.maybe_activation_offload_context:\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/transformers/trainer.py:3745\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3744\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3745\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3747\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3749\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3750\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3751\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:818\u001b[39m, in \u001b[36mSFTTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m    814\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    815\u001b[39m \u001b[33;03mCompute training loss and additionally compute token accuracies\u001b[39;00m\n\u001b[32m    816\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    817\u001b[39m mode = \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.training \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33meval\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m (loss, outputs) = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    822\u001b[39m     \u001b[38;5;66;03m# When using padding-free, the attention_mask is not present in the inputs, instead we have cu_seq_lens_q,\u001b[39;00m\n\u001b[32m    823\u001b[39m     \u001b[38;5;66;03m# cu_seq_lens_k, and max_length_k, max_length_q and position_ids.\u001b[39;00m\n\u001b[32m    824\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/transformers/trainer.py:3810\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3808\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3809\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3810\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3811\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3812\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:194\u001b[39m, in \u001b[36mDataParallel.forward\u001b[39m\u001b[34m(self, *inputs, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.module(*inputs[\u001b[32m0\u001b[39m], **module_kwargs[\u001b[32m0\u001b[39m])\n\u001b[32m    193\u001b[39m replicas = \u001b[38;5;28mself\u001b[39m.replicate(\u001b[38;5;28mself\u001b[39m.module, \u001b[38;5;28mself\u001b[39m.device_ids[: \u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gather(outputs, \u001b[38;5;28mself\u001b[39m.output_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:213\u001b[39m, in \u001b[36mDataParallel.parallel_apply\u001b[39m\u001b[34m(self, replicas, inputs, kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparallel_apply\u001b[39m(\n\u001b[32m    211\u001b[39m     \u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any\n\u001b[32m    212\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Any]:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:127\u001b[39m, in \u001b[36mparallel_apply\u001b[39m\u001b[34m(modules, inputs, kwargs_tup, devices)\u001b[39m\n\u001b[32m    125\u001b[39m     output = results[i]\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m         \u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     outputs.append(output)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/_utils.py:750\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    747\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[32m    748\u001b[39m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    749\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 97, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/peft/peft_model.py\", line 818, in forward\n    return self.get_base_model()(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/utils/generic.py\", line 969, in wrapper\n    output = func(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 730, in forward\n    outputs: BaseModelOutputWithPast = self.model(\n                                       ^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/utils/generic.py\", line 969, in wrapper\n    output = func(self, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 463, in forward\n    layer_outputs = decoder_layer(\n                    ^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/modeling_layers.py\", line 48, in __call__\n    return super().__call__(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 300, in forward\n    hidden_states = self.mlp(hidden_states)\n                    ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/models/qwen3/modeling_qwen3.py\", line 90, in forward\n    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/peft/tuners/lora/layer.py\", line 727, in forward\n    result = result + lora_B(lora_A(dropout(x))) * scaling\n                                    ^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/dropout.py\", line 70, in forward\n    return F.dropout(input, self.p, self.training, self.inplace)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/fine/uv/transformers/lib/python3.11/site-packages/torch/nn/functional.py\", line 1425, in dropout\n    _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)\n                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 94.99 GiB of which 7.31 MiB is free. Process 2156823 has 75.40 GiB memory in use. Including non-PyTorch memory, this process has 19.57 GiB memory in use. Of the allocated memory 18.42 GiB is allocated by PyTorch, and 175.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6112e099-02aa-4a2c-82dd-c45dac307658",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('model/sft/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea2c73-ceb7-4163-bc35-82417e8f0541",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 改为对两段文本分别打分，得分高的为true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "077a2ee1-069a-456d-9c7a-1b603e2d06af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer,AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ade9c6cf-7a8a-49ee-92e0-88ebdc75feab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path='/data/download-model/Qwen3-0.6B'\n",
    "model_name=model_path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70dcac4-6fbd-496e-9a00-7f712f8d7d63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at /data/download-model/Qwen3-0.6B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path, \n",
    "    num_labels=2,  # 二分类问题\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3db5002-c75f-4093-b857-def736d23c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig,get_peft_model\n",
    "\n",
    "lora_config=LoraConfig(\n",
    "    r = 16,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 32,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = 0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "343e7943-12ce-4e6a-8572-755a050efa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_peft_model(model,lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a644c31-7666-41e6-aea0-45f34dc55f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b51cee0-9fd8-4316-b8af-28fb423cef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='data/train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0f5495f-968c-41e5-bb80-a7db3082f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd=pd.read_json('data/train.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a68347ec-fb7c-46ed-a489-0ffa58f9ed0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real_text_id</th>\n",
       "      <th>file_1</th>\n",
       "      <th>file_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Dinosaur Rex was excited about his new toy set...</td>\n",
       "      <td>Analyzing how fast stars rotate within a galax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>A main focus of modern cosmology is to underst...</td>\n",
       "      <td>A key focus of modern cosmology is to understa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>APEX, as its name suggests, serves as a guide ...</td>\n",
       "      <td>APEX, as its name suggests, serves as a guide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>FORS1 and FORS2 are early instruments of the V...</td>\n",
       "      <td>FORS1 and FORS2 are early instruments of the V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>The observations of the Pluto-Charon system an...</td>\n",
       "      <td>The observations of the Pluto-Charon binary an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>The new detector system was first tested on 30...</td>\n",
       "      <td>The new detector system was first tested on 30...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  real_text_id                                             file_1  \\\n",
       "0    0             1  The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1    1             2  China\\nThe goal of this project involves achie...   \n",
       "2    2             1  Scientists can learn about how galaxies form a...   \n",
       "3    3             2  China\\nThe study suggests that multiple star s...   \n",
       "4    4             2  Dinosaur Rex was excited about his new toy set...   \n",
       "..  ..           ...                                                ...   \n",
       "90  90             2  A main focus of modern cosmology is to underst...   \n",
       "91  91             1  APEX, as its name suggests, serves as a guide ...   \n",
       "92  92             2  FORS1 and FORS2 are early instruments of the V...   \n",
       "93  93             2  The observations of the Pluto-Charon system an...   \n",
       "94  94             1  The new detector system was first tested on 30...   \n",
       "\n",
       "                                               file_2  \n",
       "0   The China relay network has released a signifi...  \n",
       "1   The project aims to achieve an accuracy level ...  \n",
       "2   Dinosaur eggshells offer clues about what dino...  \n",
       "3   The importance for understanding how stars evo...  \n",
       "4   Analyzing how fast stars rotate within a galax...  \n",
       "..                                                ...  \n",
       "90  A key focus of modern cosmology is to understa...  \n",
       "91  APEX, as its name suggests, serves as a guide ...  \n",
       "92  FORS1 and FORS2 are early instruments of the V...  \n",
       "93  The observations of the Pluto-Charon binary an...  \n",
       "94  The new detector system was first tested on 30...  \n",
       "\n",
       "[95 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abbf1246-913e-401a-952e-d3e9c333943c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pd['file_1_label'] = (train_pd['real_text_id'] == 1).astype(int)\n",
    "train_pd['file_2_label'] = (train_pd['real_text_id'] == 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bfb47118-f1c3-4cea-8da9-0f4b44fa0369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 假设原始 DataFrame 名为 df\n",
    "train_ds = pd.concat([\n",
    "    # 第一部分：file_1 与 file_1_label 组合\n",
    "    pd.DataFrame({\n",
    "        'text': train_pd['file_1'],\n",
    "        'labels': train_pd['file_1_label']\n",
    "    }),\n",
    "    # 第二部分：file_2 与 file_2_label 组合\n",
    "    pd.DataFrame({\n",
    "        'text': train_pd['file_2'],\n",
    "        'labels': train_pd['file_2_label']\n",
    "    })\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59cabdcd-288c-4c44-96e7-1081e56da03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.to_json('data/train_text_labels.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30ab0209-cd8d-4313-9a44-c8091d92a3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最长的prompt，id为： 83\n",
      "最长的prompt，长度为： 40316\n"
     ]
    }
   ],
   "source": [
    "longest_idx = train_ds['text'].str.len().idxmax()\n",
    "print(\"最长的prompt，id为：\",longest_idx)\n",
    "print(\"最长的prompt，长度为：\",len(train_ds.loc[longest_idx, 'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c218077-036f-46f6-96bf-4063be20eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a00d832a-a0f0-4176-b36e-9998a2747ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels'],\n",
       "    num_rows: 190\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4bca1d6-e093-4229-8992-b1a87d5eb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=40960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae85d0b7-fe89-45e6-806b-dccde17ee27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 190/190 [00:02<00:00, 72.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = train_ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0398089c-8292-4a5b-acad-b08e3adfab6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 190\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8f138a1-c790-4023-97d7-5548983e81af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swanlab\n",
    "\n",
    "swanlab.config.update({\n",
    "    \"model\": model_name\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "643f1418-c3f2-4603-bab6-c1e9c3971d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1, # Use GA to mimic batch size!\n",
    "    warmup_steps = 5,\n",
    "    num_train_epochs = 10, \n",
    "    learning_rate = 5e-5, \n",
    "    report_to = \"swanlab\", \n",
    "    run_name=model_name,\n",
    "    output_dir=f\"/data/finetuning/tof/{model_name}/cls\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5ee629e-650e-4c9e-9107-872c46055e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-12 11:37:08,343] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-12 11:37:09,717] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n"
     ]
    }
   ],
   "source": [
    "# 创建Trainer实例\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "efadba8d-be72-4c74-be65-135857b14df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: swanlab version 0.6.6 is available!  Upgrade: `pip install -U swanlab`    \n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Tracking run with swanlab version 0.6.4                                   \n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Run data will be saved locally in \u001b[35m\u001b[1m/home/fine/work/fake-or-real/swanlog/run-20250712_113737-a3b1799d\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: 👋 Hi \u001b[1m\u001b[39mzhangdw156\u001b[0m\u001b[0m, welcome to swanlab!\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: Syncing run \u001b[33mQwen3-0.6B\u001b[0m to the cloud\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: 🏠 View project at \u001b[34m\u001b[4mhttps://swanlab.cn/@zhangdw156/fake-or-real\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[34mswanlab\u001b[0m\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://swanlab.cn/@zhangdw156/fake-or-real/runs/02vqs1cv4nocgz77re690\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Show Iframe</title>\n",
       "    \n",
       "        <script>\n",
       "            function showIframe() {\n",
       "                var iframeHtml = '<iframe src=\"https://swanlab.cn/@zhangdw156/fake-or-real/runs/02vqs1cv4nocgz77re690\" width=100% height=\"600\" frameborder=\"no\"></iframe>';\n",
       "                document.getElementById('iframeContainer').innerHTML = iframeHtml;\n",
       "            }\n",
       "        </script>\n",
       "        \n",
       "</head>\n",
       "<body>\n",
       "    <style>\n",
       "        .interactive-button {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            height: 36px;\n",
       "            border: 0px;\n",
       "            background-color: #2c8f63;\n",
       "            color: white;\n",
       "            padding: 10px 20px;\n",
       "            transition: background-color 0.3s, transform 0.2s;\n",
       "        }\n",
       "\n",
       "        .interactive-button:hover {\n",
       "            background-color: #5cab87;\n",
       "            cursor: pointer;\n",
       "        }\n",
       "\n",
       "        .interactive-button:active { background-color: #217952; transform: scale(0.96); } </style> <br> <button \n",
       "        onclick=\"showIframe()\" class=\"interactive-button\"> <svg style=\"height: 16px; margin-right: 8px;\" viewBox=\"0 0 \n",
       "        46 46\" fill=\"none\"> <path d=\"M10.8439 21.1974C10.6414 21.2854 10.4477 21.3925 10.2655 21.5173L10.2069 \n",
       "        21.5652C10.1839 21.58 10.1625 21.5969 10.1429 21.6159C6.29135 24.6118 4.22831 29.4416 5.32646 34.282C5.94656 \n",
       "        37.0577 7.50461 39.5348 9.73801 41.2958C11.9714 43.0568 14.7436 43.994 17.5874 43.9495H18.0219C19.8864 \n",
       "        43.8697 21.7087 43.3694 23.3526 42.486C24.9964 41.6026 26.4193 40.3589 27.5147 38.848C28.61 37.3371 29.3496 \n",
       "        35.598 29.678 33.761C30.0065 31.9239 29.9153 30.0363 29.4112 28.2395C28.9181 26.4723 27.8919 24.8437 26.9937 \n",
       "        23.2551C25.4158 20.4653 23.8343 17.6764 22.2492 14.8884C21.7801 14.0647 21.3057 13.2465 20.8419 \n",
       "        12.4228C20.2315 11.3353 19.2746 10.1519 19.224 8.86183C19.1733 7.57176 20.2235 6.32701 21.5082 \n",
       "        6.07912C23.9284 5.61801 25.0639 8.24078 25.0693 8.23812C25.363 8.94035 25.9123 9.50489 26.6063 \n",
       "        9.81764C27.3002 10.1304 28.087 10.168 28.8077 9.92298C29.5283 9.67791 30.1291 9.1684 30.4885 8.49743C30.8479 \n",
       "        7.82646 30.9392 7.04405 30.7439 6.30835C30.1514 4.37314 28.9133 2.69953 27.2363 1.56656C25.7615 0.511704 \n",
       "        23.9847 -0.0372109 22.1719 0.00195984C20.9049 0.00893199 19.6532 0.27989 18.4967 0.797557C17.3402 1.31522 \n",
       "        16.3043 2.06823 15.4551 3.00856C14.49 4.08707 13.7984 5.38193 13.4389 6.78385C13.0794 8.18576 13.0624 9.6536 \n",
       "        13.3894 11.0635C13.52 11.593 13.6984 12.1095 13.9225 12.6067C14.5595 14.0514 15.4951 15.3681 16.284 \n",
       "        16.7355C17.2525 18.4147 18.2209 20.0948 19.1893 21.7758C20.1578 23.4568 21.1351 25.1449 22.1213 \n",
       "        26.8401C22.9209 28.2421 23.7925 29.4682 23.8805 31.1528C23.9175 32.0513 23.7682 32.9479 23.4419 \n",
       "        33.7859C23.1156 34.6239 22.6194 35.3854 21.9845 36.0223C21.3496 36.6592 20.5897 37.1578 19.7527 \n",
       "        37.4868C18.9157 37.8157 18.0196 37.9678 17.121 37.9336C14.0024 37.7923 11.6488 35.4814 11.1744 32.4588C10.58 \n",
       "        28.6419 13.552 26.5469 13.552 26.5469C14.1782 26.1785 14.6497 25.5955 14.8791 24.906C15.1084 24.2166 15.0801 \n",
       "        23.4673 14.7993 22.7971C14.5186 22.127 14.0044 21.5813 13.3521 21.2611C12.6998 20.941 11.9536 20.8682 11.2517 \n",
       "        21.0561C11.1174 21.0939 10.9856 21.1402 10.8572 21.1947\" fill=\"white\" /> <path d=\"M42.8101 31.5968C42.8109 \n",
       "        30.5198 42.7218 29.4445 42.5435 28.3823C42.2663 26.7069 41.7464 25.0808 41.0002 23.5552C40.5524 22.6463 \n",
       "        39.9874 21.7374 39.1024 21.2417C38.6593 20.9919 38.1589 20.8617 37.6502 20.8639C37.1416 20.8661 36.6423 \n",
       "        21.0006 36.2013 21.2541C35.7604 21.5077 35.393 21.8716 35.1352 22.3101C34.8775 22.7485 34.7382 23.2466 \n",
       "        34.7312 23.7552C34.7072 24.8773 35.3149 25.8875 35.768 26.9217C36.5212 28.6453 36.8623 30.5208 36.7642 \n",
       "        32.3993C36.6661 34.2777 36.1315 36.1075 35.2029 37.7433C35.146 37.8404 35.0952 37.941 35.051 38.0445C34.8623 \n",
       "        38.4842 34.7635 38.9573 34.7605 39.4358C34.7802 40.1222 35.0356 40.7808 35.4835 41.3011C35.9315 41.8214 \n",
       "        36.5449 42.1717 37.2207 42.2932C38.8759 42.589 40.1899 41.347 40.8856 39.9609C42.1643 37.3589 42.823 34.4961 \n",
       "        42.8101 31.5968Z\" fill=\"white\" /> <path d=\"M28.2309 11.8938C28.1761 11.9043 28.1218 11.9176 28.0683 \n",
       "        11.9338C27.9593 11.9642 27.8611 12.0249 27.7851 12.1088C27.7091 12.1928 27.6584 12.2965 27.6389 \n",
       "        12.408C27.6193 12.5195 27.6318 12.6343 27.6748 12.7391C27.7178 12.8438 27.7895 12.9343 27.8818 \n",
       "        12.9999C29.2375 14.0252 30.3809 15.3043 31.2482 16.7662C31.4838 17.1677 31.6888 17.5865 31.8612 \n",
       "        18.0189C32.0052 18.3921 32.1971 18.8799 32.6822 18.8532C33.0607 18.8346 33.2153 18.512 33.3192 \n",
       "        18.1895C33.8137 16.5125 33.9678 14.7534 33.7723 13.0159C33.6331 12.0693 33.4155 11.1359 33.122 \n",
       "        10.2252C33.0775 10.0047 32.9744 9.80029 32.8235 9.6335C32.7273 9.54627 32.6054 9.49262 32.4761 9.4806C32.3468 \n",
       "        9.46859 32.2171 9.49886 32.1065 9.56687C32.0016 9.65188 31.9115 9.75365 31.8399 9.86806C31.3956 10.4658 \n",
       "        30.825 10.9581 30.1687 11.3101C29.8377 11.4861 29.4893 11.6272 29.1292 11.7312C28.828 11.8192 28.5215 11.8325 \n",
       "        28.2309 11.8938Z\" fill=\"white\" /> </svg> Display SwanLab Board </button> <br> <div \n",
       "        id=\"iframeContainer\"></div> </body> </html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 94.99 GiB of which 7.38 MiB is free. Process 3956245 has 92.28 GiB memory in use. Including non-PyTorch memory, this process has 2.69 GiB memory in use. Of the allocated memory 1.54 GiB is allocated by PyTorch, and 65.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/transformers/trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/transformers/trainer.py:2555\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2548\u001b[39m context = (\n\u001b[32m   2549\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2551\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2552\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2553\u001b[39m )\n\u001b[32m   2554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2555\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2558\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2559\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2560\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2561\u001b[39m ):\n\u001b[32m   2562\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2563\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/transformers/trainer.py:3745\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3744\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3745\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3747\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3749\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3750\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3751\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/transformers/trainer.py:3810\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3808\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3809\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3810\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3811\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3812\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:193\u001b[39m, in \u001b[36mDataParallel.forward\u001b[39m\u001b[34m(self, *inputs, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.device_ids) == \u001b[32m1\u001b[39m:\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.module(*inputs[\u001b[32m0\u001b[39m], **module_kwargs[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m replicas = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m outputs = \u001b[38;5;28mself\u001b[39m.parallel_apply(replicas, inputs, module_kwargs)\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gather(outputs, \u001b[38;5;28mself\u001b[39m.output_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[39m, in \u001b[36mDataParallel.replicate\u001b[39m\u001b[34m(self, module, device_ids)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreplicate\u001b[39m(\n\u001b[32m    198\u001b[39m     \u001b[38;5;28mself\u001b[39m, module: T, device_ids: Sequence[Union[\u001b[38;5;28mint\u001b[39m, torch.device]]\n\u001b[32m    199\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[T]:\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/parallel/replicate.py:126\u001b[39m, in \u001b[36mreplicate\u001b[39m\u001b[34m(network, devices, detach)\u001b[39m\n\u001b[32m    124\u001b[39m params = \u001b[38;5;28mlist\u001b[39m(network.parameters())\n\u001b[32m    125\u001b[39m param_indices = {param: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(params)}\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m param_copies = \u001b[43m_broadcast_coalesced_reshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m buffers = \u001b[38;5;28mlist\u001b[39m(network.buffers())\n\u001b[32m    129\u001b[39m buffers_rg: \u001b[38;5;28mlist\u001b[39m[torch.Tensor] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/parallel/replicate.py:95\u001b[39m, in \u001b[36m_broadcast_coalesced_reshape\u001b[39m\u001b[34m(tensors, devices, detach)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m     \u001b[38;5;66;03m# Use the autograd function to broadcast if not detach\u001b[39;00m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensors) > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         tensor_copies = \u001b[43mBroadcast\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m     97\u001b[39m             tensor_copies[i : i + \u001b[38;5;28mlen\u001b[39m(tensors)]\n\u001b[32m     98\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tensor_copies), \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[32m     99\u001b[39m         ]\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/autograd/function.py:575\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    574\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:23\u001b[39m, in \u001b[36mBroadcast.forward\u001b[39m\u001b[34m(ctx, target_gpus, *inputs)\u001b[39m\n\u001b[32m     21\u001b[39m ctx.num_inputs = \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[32m     22\u001b[39m ctx.input_device = inputs[\u001b[32m0\u001b[39m].get_device()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m outputs = \u001b[43mcomm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_coalesced\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtarget_gpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m non_differentiables = []\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, input_requires_grad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ctx.needs_input_grad[\u001b[32m1\u001b[39m:]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/uv/transformers/lib/python3.11/site-packages/torch/nn/parallel/comm.py:66\u001b[39m, in \u001b[36mbroadcast_coalesced\u001b[39m\u001b[34m(tensors, devices, buffer_size)\u001b[39m\n\u001b[32m     64\u001b[39m devices = [_get_device_index(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m devices]\n\u001b[32m     65\u001b[39m tensors = [_handle_complex(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tensors]\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_broadcast_coalesced\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 3 has a total capacity of 94.99 GiB of which 7.38 MiB is free. Process 3956245 has 92.28 GiB memory in use. Including non-PyTorch memory, this process has 2.69 GiB memory in use. Of the allocated memory 1.54 GiB is allocated by PyTorch, and 65.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f915c6-5dc4-41be-8cdd-d9fafea5462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(f'model/{model_name}/cls/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b8e65-ce8a-49b4-9df1-8a3cc3ef18e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 验证分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5145bfac-02cb-4b35-b426-24dec93b3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from transformers import pipeline,AutoModelForSequenceClassification,AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7987c834-03d5-402f-ac38-093cfb35339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"/data/download-model/Qwen3-0.6B\"\n",
    "model_name=model_path.split('/')[-1]\n",
    "lora_path=\"model/Qwen3-0.6B/cls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3457671-41de-407c-a8d8-ded47467b72a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at /data/download-model/Qwen3-0.6B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path, \n",
    "    num_labels=2,  # 二分类问题\n",
    ")\n",
    "\n",
    "# model=PeftModel.from_pretrained(model,lora_path)\n",
    "# model=model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bba4a866-258e-4425-ab23-7f738a30cd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/home/fine/uv/transformers/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_all_scores=True,  # 返回所有类别的分数（0和1的概率）\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f884fe4a-2354-4597-bcc6-9f381e9ca56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_json('data/train_text_labels.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfc128a9-555f-4042-8f96-a9a0333e1107",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['text'].replace('', ' ')  # 替换空字符串\n",
    "train_df_1=train_df[:95]\n",
    "train_df_2=train_df[95:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0087a812-e99f-4e9b-af2a-e062ec800bb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outpus_1=classifier(train_df_1['text'].tolist())\n",
    "outpus_2=classifier(train_df_2['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b24c1ec7-2da0-465d-bc29-8541693ba3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_1 = [row[1]['score'] for row in outpus_1]\n",
    "predict_2 = [row[1]['score'] for row in outpus_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ff35034-cd39-4756-afc2-b3ae7ae1eed6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_csv=pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f86dcd2-5c2b-420f-b15b-2d25866cce36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real_text_id</th>\n",
       "      <th>predict_1</th>\n",
       "      <th>predict_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995256</td>\n",
       "      <td>0.976252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992228</td>\n",
       "      <td>0.980944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993001</td>\n",
       "      <td>0.994762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.943174</td>\n",
       "      <td>0.978689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997313</td>\n",
       "      <td>0.988094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>0.979684</td>\n",
       "      <td>0.980632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992949</td>\n",
       "      <td>0.226817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>0.759456</td>\n",
       "      <td>0.980790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997498</td>\n",
       "      <td>0.995895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989446</td>\n",
       "      <td>0.992426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  real_text_id  predict_1  predict_2\n",
       "0    0             1   0.995256   0.976252\n",
       "1    1             2   0.992228   0.980944\n",
       "2    2             1   0.993001   0.994762\n",
       "3    3             2   0.943174   0.978689\n",
       "4    4             2   0.997313   0.988094\n",
       "..  ..           ...        ...        ...\n",
       "90  90             2   0.979684   0.980632\n",
       "91  91             1   0.992949   0.226817\n",
       "92  92             2   0.759456   0.980790\n",
       "93  93             2   0.997498   0.995895\n",
       "94  94             1   0.989446   0.992426\n",
       "\n",
       "[95 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv['predict_1']=predict_1\n",
    "train_csv['predict_2']=predict_2\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cf01efe-4a90-4a80-8970-6b7f688930fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real_text_id</th>\n",
       "      <th>predict_1</th>\n",
       "      <th>predict_2</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995256</td>\n",
       "      <td>0.976252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.992228</td>\n",
       "      <td>0.980944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993001</td>\n",
       "      <td>0.994762</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.943174</td>\n",
       "      <td>0.978689</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997313</td>\n",
       "      <td>0.988094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>0.979684</td>\n",
       "      <td>0.980632</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992949</td>\n",
       "      <td>0.226817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>0.759456</td>\n",
       "      <td>0.980790</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997498</td>\n",
       "      <td>0.995895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989446</td>\n",
       "      <td>0.992426</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  real_text_id  predict_1  predict_2  predict\n",
       "0    0             1   0.995256   0.976252        1\n",
       "1    1             2   0.992228   0.980944        1\n",
       "2    2             1   0.993001   0.994762        2\n",
       "3    3             2   0.943174   0.978689        2\n",
       "4    4             2   0.997313   0.988094        1\n",
       "..  ..           ...        ...        ...      ...\n",
       "90  90             2   0.979684   0.980632        2\n",
       "91  91             1   0.992949   0.226817        1\n",
       "92  92             2   0.759456   0.980790        2\n",
       "93  93             2   0.997498   0.995895        1\n",
       "94  94             1   0.989446   0.992426        2\n",
       "\n",
       "[95 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 当 predict_1 > predict_2 时为1，否则为2\n",
    "train_csv['predict'] = np.where(train_csv['predict_1'] > train_csv['predict_2'], 1, 2)\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f11a4cac-4fb1-45c6-92a7-b57dc8f165d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在训练集上的准确率为: 0.57895\n"
     ]
    }
   ],
   "source": [
    "train_csv['real_text_id']=train_csv['real_text_id'].astype(int)\n",
    "accuracy = (train_csv['real_text_id'] == train_csv['predict']).mean()\n",
    "print(f\"在训练集上的准确率为: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5773d7f3-7af7-4ff4-a798-4c0115beddbb",
   "metadata": {},
   "source": [
    "## 用sft模型进行推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5375629e-ea63-4921-ad7d-bb354032c457",
   "metadata": {},
   "source": [
    "## 把额外数据构造成本比赛的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d168e803-4f2d-40cd-9cb0-76fb8fdd378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a5e0cefd-f6cb-4123-96d8-028e6b18d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_path='data/extra_train.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4dc5b0db-344b-4098-b815-5bfb19af93d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data=pd.read_json(extra_path,orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a0fb7d3-6f39-4f8a-a050-e341c54716b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S. cities. Here's more about Seattle's snowfa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This paper delves into the interpretability a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You could sell this toy to all your friends a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My time to shine . The term \" Rockefeller Rep...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This case raised several ethical and legal qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>Each letter of the alphabet is assigned to a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>That's because people need to make sure that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>As a general rule, you must choose between a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>This can be used for international trade and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>Imagine you have a tube of toothpaste. When y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0       S. cities. Here's more about Seattle's snowfa...      1\n",
       "1       This paper delves into the interpretability a...      1\n",
       "2       You could sell this toy to all your friends a...      1\n",
       "3       My time to shine . The term \" Rockefeller Rep...      0\n",
       "4       This case raised several ethical and legal qu...      1\n",
       "...                                                  ...    ...\n",
       "27995   Each letter of the alphabet is assigned to a ...      1\n",
       "27996   That's because people need to make sure that ...      1\n",
       "27997   As a general rule, you must choose between a ...      0\n",
       "27998   This can be used for international trade and ...      1\n",
       "27999   Imagine you have a tube of toothpaste. When y...      1\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5d5e646b-d915-47c1-a9af-1ae55856abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_extra_data = extra_data[extra_data['label'] == 0].copy()  # label=0的所有数据\n",
    "ai_extra_data = extra_data[extra_data['label'] == 1].copy()  # label=1的所有数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4dc1a60a-0fe2-4aae-bf51-a363398e7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pairs_per_type = min(len(man_extra_data), len(ai_extra_data))//2  # 每种配对类型的最大数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f679439-94e4-434e-afcd-decb508f1beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6546"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pairs_per_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ef6610ee-15fe-4445-9ee5-5232096d6b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample0_type1 = man_extra_data.sample(n=max_pairs_per_type, replace=False, random_state=np.random.randint(0, 1000))  # 随机采样label0\n",
    "sample1_type1 = ai_extra_data.sample(n=max_pairs_per_type, replace=False, random_state=np.random.randint(0, 1000))  # 随机采样label1\n",
    "pairs_type1 = pd.DataFrame({\n",
    "    'file_1': sample0_type1['text'].values,\n",
    "    'file_2': sample1_type1['text'].values,\n",
    "    'real_text_id':1\n",
    "})\n",
    "\n",
    "# 类型2：text1（label1） + text2（label0）\n",
    "sample1_type2 = ai_extra_data.sample(n=max_pairs_per_type, replace=False, random_state=np.random.randint(0, 1000))  # 随机采样label1（与type1不重复）\n",
    "sample0_type2 = man_extra_data.sample(n=max_pairs_per_type, replace=False, random_state=np.random.randint(0, 1000))  # 随机采样label0（与type1不重复）\n",
    "pairs_type2 = pd.DataFrame({\n",
    "    'file_1': sample1_type2['text'].values,\n",
    "    'file_2': sample0_type2['text'].values,\n",
    "    'real_text_id':2\n",
    "})\n",
    "\n",
    "# 合并两种配对并打乱顺序\n",
    "final_pairs = pd.concat([pairs_type1, pairs_type2], ignore_index=True)\n",
    "final_pairs = final_pairs.sample(frac=1, random_state=np.random.randint(0, 1000)).reset_index(drop=True)  # 打乱顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4d0f37c4-41bb-4857-88b5-93fca8a34cda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_1</th>\n",
       "      <th>file_2</th>\n",
       "      <th>real_text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Believe it or not, unless you directly contac...</td>\n",
       "      <td>This could include filing a lawsuit against t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sanskrit, as one of the oldest Indo-European ...</td>\n",
       "      <td>Medically speaking a seizure is when the elec...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Shirley Temple short subject would likely c...</td>\n",
       "      <td>- If you criminalize alcohol / drug use or sm...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It 's three fold : * Stuff is cheaper to mass...</td>\n",
       "      <td>Miami's vibrant music scene has long been a m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>That 's the problem of consciousness : we jus...</td>\n",
       "      <td>Different religions have different ways of pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13087</th>\n",
       "      <td>The deadline to mail is February 15. However,...</td>\n",
       "      <td>For years, he was a ghost, a rumor whispered ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13088</th>\n",
       "      <td>There are many different systems , but the ba...</td>\n",
       "      <td>The company has reportedly pushed back the re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13089</th>\n",
       "      <td>Barrels breathe . They expand and contract wi...</td>\n",
       "      <td>Here’s how you might continue: 1. Reservation...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13090</th>\n",
       "      <td>An activity tracker, also known as a fitness ...</td>\n",
       "      <td>While you haven't mentioned the title of the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13091</th>\n",
       "      <td>Some might have used natural barriers like sh...</td>\n",
       "      <td>You can have multiple W2 forms on the same ta...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file_1  \\\n",
       "0       Believe it or not, unless you directly contac...   \n",
       "1       Sanskrit, as one of the oldest Indo-European ...   \n",
       "2       A Shirley Temple short subject would likely c...   \n",
       "3       It 's three fold : * Stuff is cheaper to mass...   \n",
       "4       That 's the problem of consciousness : we jus...   \n",
       "...                                                  ...   \n",
       "13087   The deadline to mail is February 15. However,...   \n",
       "13088   There are many different systems , but the ba...   \n",
       "13089   Barrels breathe . They expand and contract wi...   \n",
       "13090   An activity tracker, also known as a fitness ...   \n",
       "13091   Some might have used natural barriers like sh...   \n",
       "\n",
       "                                                  file_2  real_text_id  \n",
       "0       This could include filing a lawsuit against t...             1  \n",
       "1       Medically speaking a seizure is when the elec...             2  \n",
       "2       - If you criminalize alcohol / drug use or sm...             2  \n",
       "3       Miami's vibrant music scene has long been a m...             1  \n",
       "4       Different religions have different ways of pr...             1  \n",
       "...                                                  ...           ...  \n",
       "13087   For years, he was a ghost, a rumor whispered ...             1  \n",
       "13088   The company has reportedly pushed back the re...             1  \n",
       "13089   Here’s how you might continue: 1. Reservation...             1  \n",
       "13090   While you haven't mentioned the title of the ...             1  \n",
       "13091   You can have multiple W2 forms on the same ta...             2  \n",
       "\n",
       "[13092 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看结果\n",
    "final_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8d84429b-9649-48e6-b3fd-93dd42878fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pairs[\"id\"] = final_pairs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ec7c2454-4abe-45e2-be77-7d25029fbc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pairs.to_json('data/extra_train.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523ed3c-ff20-4178-8cc9-e3562fda3402",
   "metadata": {},
   "source": [
    "## 未完待续"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "337bd963-734c-4a06-8bb0-2f147fa4f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "00e420bc-e38a-4d35-b494-9f44f2865458",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_time=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "42fed888-141f-432d-9ad2-30abbbc85996",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3e4e7b93-4649-4791-9e34-1ee4e283a370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'处理时间为: 24.07'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"处理时间为: {(end_time-begin_time):.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f0a4a-116c-43aa-a2e7-a8f1a3e70f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
